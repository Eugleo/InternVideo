{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f86bc499",
   "metadata": {},
   "source": [
    "## download ViCILP weights and put its pth file in viclip folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e7a90379-d9ee-45d9-9073-7ed5132fa6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import torch\n",
    "from IPython.display import HTML, Video, display, display_html\n",
    "from ipywidgets import GridspecLayout, Output\n",
    "\n",
    "from viclip import (\n",
    "    _frame_from_video,\n",
    "    frames2tensor,\n",
    "    get_text_feat_dict,\n",
    "    get_viclip,\n",
    "    get_vid_feat,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4a9ecb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = get_viclip(\"l\", \"models/ViCLIP-L_InternVid-FLT-10M.pth\")\n",
    "\n",
    "GOALS = [\n",
    "    \"A stick model of a dog actively running in grass.\",\n",
    "    \"A stick model of a dog trying to move in grass but failing.\",\n",
    "    \"A stick model of a dog on a grey background actively running.\",\n",
    "    \"A stick model of a dog on a grey background trying to move but failing.\",\n",
    "    \"A stick model of a dog doing weird things in grass.\",\n",
    "    \"A stick model of a pair of legs, attempting to walk.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d497aca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from viclip import retrieve_text\n",
    "\n",
    "\n",
    "def get_label_probs(video_path, labels, model=MODEL):\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    frames = [x for x in _frame_from_video(video)]\n",
    "    texts, probs = retrieve_text(frames, labels, model, topk=len(labels))\n",
    "\n",
    "    result = []\n",
    "    for t, p in zip(texts, probs):\n",
    "        result.append(f\"[{p:.2f}]: {t}\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_similarity_score(video_path, labels, model=MODEL):\n",
    "    results = []\n",
    "    for label in labels:\n",
    "        device = torch.device(\"cuda\")\n",
    "\n",
    "        video = cv2.VideoCapture(video_path)\n",
    "        frames = [x for x in _frame_from_video(video)]\n",
    "\n",
    "        clip, tokenizer = model[\"viclip\"], model[\"tokenizer\"]\n",
    "        clip = clip.to(device)\n",
    "\n",
    "        v = get_vid_feat(frames2tensor(frames, device=device), clip)\n",
    "        t = get_text_feat_dict([label], clip, tokenizer)[label]\n",
    "\n",
    "        results.append(torch.nn.functional.cosine_similarity(v, t).item())\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "909f2075",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pl.DataFrame({\"path\": [str(p) for p in Path(\"videos\").glob(\"*.mp4\")]})\n",
    "# data = data.with_columns(\n",
    "#     sim=pl.col(\"path\").map_elements(\n",
    "#         lambda p: get_similarity_score(video_path=p, labels=GOALS)\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2e6024ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1781f7af24a45f9946a39b9b07b0149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridspecLayout(children=(Output(layout=Layout(grid_area='widget001')), Output(layout=Layout(grid_area='widget0â€¦"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridspecLayout(len(data), 2)\n",
    "\n",
    "for i, row in enumerate(data.iter_rows(named=True)):\n",
    "    out = Output()\n",
    "    with out:\n",
    "        display(Video(row[\"path\"], width=150, html_attributes=\"loop autoplay muted\"))\n",
    "    grid[i, 0] = out\n",
    "    label_probs = get_label_probs(row[\"path\"], GOALS)\n",
    "    label_str = \"<br>\".join(label_probs)\n",
    "    o2 = Output()\n",
    "    with o2:\n",
    "        display_html(label_str, raw=True)\n",
    "    grid[i, 1] = o2\n",
    "\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "31e380e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "import torch\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
